{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSA 2024 Phase 2 - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.1.tar.gz (36.1 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [22 lines of output]\n",
      "      + meson setup C:\\Users\\86198\\AppData\\Local\\Temp\\pip-install-su8ggdzl\\matplotlib_55ac7e5c83754f66a9c9ebccb2f777d4 C:\\Users\\86198\\AppData\\Local\\Temp\\pip-install-su8ggdzl\\matplotlib_55ac7e5c83754f66a9c9ebccb2f777d4\\.mesonpy-5ixkmc2w -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\86198\\AppData\\Local\\Temp\\pip-install-su8ggdzl\\matplotlib_55ac7e5c83754f66a9c9ebccb2f777d4\\.mesonpy-5ixkmc2w\\meson-python-native-file.ini\n",
      "      The Meson build system\n",
      "      Version: 1.5.1\n",
      "      Source dir: C:\\Users\\86198\\AppData\\Local\\Temp\\pip-install-su8ggdzl\\matplotlib_55ac7e5c83754f66a9c9ebccb2f777d4\n",
      "      Build dir: C:\\Users\\86198\\AppData\\Local\\Temp\\pip-install-su8ggdzl\\matplotlib_55ac7e5c83754f66a9c9ebccb2f777d4\\.mesonpy-5ixkmc2w\n",
      "      Build type: native build\n",
      "      Program python3 found: YES\n",
      "      Project name: matplotlib\n",
      "      Project version: 3.9.1\n",
      "      WARNING: Failed to activate VS environment: Could not find C:\\Program Files (x86)\\Microsoft Visual Studio\\Installer\\vswhere.exe\n",
      "      \n",
      "      ..\\meson.build:1:0: ERROR: Unknown compiler(s): [['icl'], ['cl'], ['cc'], ['gcc'], ['clang'], ['clang-cl'], ['pgcc']]\n",
      "      The following exception(s) were encountered:\n",
      "      Running `icl \"\"` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `cc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `gcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `clang --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `clang-cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `pgcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      \n",
      "      A full log can be found at C:\\Users\\86198\\AppData\\Local\\Temp\\pip-install-su8ggdzl\\matplotlib_55ac7e5c83754f66a9c9ebccb2f777d4\\.mesonpy-5ixkmc2w\\meson-logs\\meson-log.txt\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas seaborn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Find all variables and understand them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Load the datasets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m features_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m sales_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m stores_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstores.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "## Load the datasets\n",
    "features_df = pd.read_csv('features.csv')\n",
    "sales_df = pd.read_csv('sales.csv')\n",
    "stores_df = pd.read_csv('stores.csv')\n",
    "\n",
    "# Convert 'Date' columns to datetime format\n",
    "features_df['Date'] = pd.to_datetime(features_df['Date'])\n",
    "sales_df['Date'] = pd.to_datetime(sales_df['Date'])\n",
    "\n",
    "# Display the first ten instances of each dataset\n",
    "print(\"Features DataFrame:\")\n",
    "print(features_df.head(10))\n",
    "print(\"\\nSales DataFrame:\")\n",
    "print(sales_df.head(10))\n",
    "print(\"\\nStores DataFrame:\")\n",
    "print(stores_df.head(10))\n",
    "\n",
    "# Key statistical measures for features dataset\n",
    "print(\"Features DataFrame - Statistical Measures:\")\n",
    "print(features_df.describe())\n",
    "\n",
    "# Key statistical measures for sales dataset\n",
    "print(\"\\nSales DataFrame - Statistical Measures:\")\n",
    "print(sales_df.describe())\n",
    "\n",
    "# Key statistical measures for stores dataset\n",
    "print(\"\\nStores DataFrame - Statistical Measures:\")\n",
    "print(stores_df.describe())\n",
    "# Visualization of numerical columns in the features dataset\n",
    "numeric_features = features_df.select_dtypes(include=['float64', 'int64'])\n",
    "numeric_features.hist(figsize=(15, 10))\n",
    "plt.show()\n",
    "\n",
    "# Visualization of numerical columns in the sales dataset\n",
    "numeric_sales = sales_df.select_dtypes(include=['float64', 'int64'])\n",
    "numeric_sales.hist(figsize=(15, 10))\n",
    "plt.show()\n",
    "\n",
    "# Visualization of numerical columns in the stores dataset\n",
    "numeric_stores = stores_df.select_dtypes(include=['float64', 'int64'])\n",
    "numeric_stores.hist(figsize=(15, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Handle missing values\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m features_df \u001b[38;5;241m=\u001b[39m \u001b[43mfeatures_df\u001b[49m\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      3\u001b[0m sales_df \u001b[38;5;241m=\u001b[39m sales_df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      4\u001b[0m stores_df \u001b[38;5;241m=\u001b[39m stores_df\u001b[38;5;241m.\u001b[39mdropna()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features_df' is not defined"
     ]
    }
   ],
   "source": [
    "## Handle missing values\n",
    "features_df = features_df.dropna()\n",
    "sales_df = sales_df.dropna()\n",
    "stores_df = stores_df.dropna()\n",
    "\n",
    "# Remove outliers function\n",
    "def remove_outliers(df):\n",
    "    numeric_df = df.select_dtypes(include=['float64', 'int64'])  # Select only numeric columns\n",
    "    Q1 = numeric_df.quantile(0.25)\n",
    "    Q3 = numeric_df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[~((numeric_df < lower_bound) | (numeric_df > upper_bound)).any(axis=1)]\n",
    "\n",
    "# Remove outliers from the datasets\n",
    "features_df = remove_outliers(features_df)\n",
    "sales_df = remove_outliers(sales_df)\n",
    "stores_df = remove_outliers(stores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cleaned data\n",
    "numeric_cols = features_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Histograms of cleaned numerical columns\n",
    "features_df[numeric_cols].hist(bins=20, figsize=(15, 10))\n",
    "plt.suptitle('Histograms of Cleaned Numerical Columns')\n",
    "plt.show()\n",
    "\n",
    "# Boxplots of cleaned numerical columns\n",
    "plt.figure(figsize=(15, 10))\n",
    "features_df[numeric_cols].boxplot()\n",
    "plt.title('Boxplots of Cleaned Numerical Columns')\n",
    "plt.show()\n",
    "\n",
    "# Monthly sales trends by store\n",
    "sales_df['Month'] = sales_df['Date'].dt.to_period('M')  # Converted 'Date' to monthly period\n",
    "store_monthly_sales = sales_df.groupby(['Store', 'Month'])['Weekly_Sales'].sum().unstack()\n",
    "store_monthly_sales.T.plot(figsize=(14, 7))\n",
    "plt.title('Monthly Sales Trends by Store')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Monthly sales trends by department\n",
    "dept_monthly_sales = sales_df.groupby(['Dept', 'Month'])['Weekly_Sales'].sum().unstack()\n",
    "dept_monthly_sales.T.plot(figsize=(14, 7), legend=False)\n",
    "plt.title('Monthly Sales Trends by Department')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.show()\n",
    "\n",
    "# Check the columns and data types in features_df\n",
    "print(\"Columns in features_df:\")\n",
    "print(features_df.columns)\n",
    "print(\"Data types in features_df:\")\n",
    "print(features_df.dtypes)\n",
    "\n",
    "# Ensure 'IsHoliday' is a column in features_df\n",
    "if 'IsHoliday' not in features_df.columns:\n",
    "    print(\"'IsHoliday' column is missing from features_df.\")\n",
    "else:\n",
    "    print(\"'IsHoliday' column is present in features_df.\")\n",
    "\n",
    "# Check for missing values in 'IsHoliday' before merging\n",
    "print(\"Missing values in 'IsHoliday' before merging:\")\n",
    "print(features_df['IsHoliday'].isnull().sum())\n",
    "\n",
    "# Merge sales and features datasets on 'Store' and 'Date'\n",
    "merged_df = pd.merge(sales_df, features_df[['Store', 'Date', 'IsHoliday']], on=['Store', 'Date'])\n",
    "\n",
    "# Rename columns to avoid confusion\n",
    "merged_df.rename(columns={'IsHoliday_x': 'IsHoliday_sales', 'IsHoliday_y': 'IsHoliday'}, inplace=True)\n",
    "\n",
    "# Check if the 'IsHoliday' column is in the merged DataFrame\n",
    "print(\"Columns in merged DataFrame:\")\n",
    "print(merged_df.columns)\n",
    "\n",
    "# Display the first few rows of the merged DataFrame to inspect\n",
    "print(\"First few rows of merged DataFrame:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# Check for any missing values in 'IsHoliday' after merging\n",
    "print(\"Missing values in 'IsHoliday' after merging:\")\n",
    "print(merged_df['IsHoliday'].isnull().sum())\n",
    "\n",
    "# Weekly Sales During Holidays vs Non-Holidays\n",
    "plt.figure(figsize=(14, 7))\n",
    "# Create separate dataframes for holiday and non-holiday\n",
    "holiday_sales = merged_df[merged_df['IsHoliday'] == True]\n",
    "non_holiday_sales = merged_df[merged_df['IsHoliday'] == False]\n",
    "\n",
    "# Plotting\n",
    "sns.lineplot(data=non_holiday_sales, x='Date', y='Weekly_Sales', label='Non-Holiday', color='blue')\n",
    "sns.lineplot(data=holiday_sales, x='Date', y='Weekly_Sales', label='Holiday', color='orange')\n",
    "\n",
    "# Adding the legend\n",
    "plt.legend(title='Is Holiday')\n",
    "plt.title('Weekly Sales During Holidays vs Non-Holidays')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Weekly Sales')\n",
    "plt.show()\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numeric_features = features_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "numeric_sales = sales_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "numeric_stores = stores_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "features_df[numeric_features] = scaler.fit_transform(features_df[numeric_features])\n",
    "sales_df[numeric_sales] = scaler.fit_transform(sales_df[numeric_sales])\n",
    "stores_df[numeric_stores] = scaler.fit_transform(stores_df[numeric_stores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identify correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for features dataset\n",
    "numeric_features_df = features_df.select_dtypes(include=['float64', 'int64'])\n",
    "corr_features = numeric_features_df.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_features, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap - Features')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix for sales dataset\n",
    "numeric_sales_df = sales_df.select_dtypes(include=['float64', 'int64'])\n",
    "corr_sales = numeric_sales_df.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_sales, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap - Sales')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix for stores dataset\n",
    "numeric_stores_df = stores_df.select_dtypes(include=['float64', 'int64'])\n",
    "corr_stores = numeric_stores_df.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_stores, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap - Stores')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1a2242e7081b4f0929018da2a8cc567af1f3cf95e7af08c98cfb4addbb6241a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
